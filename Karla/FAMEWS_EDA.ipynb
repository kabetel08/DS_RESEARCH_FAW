{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geopandas\n",
    "#!pip install rasterstats\n",
    "#!pip install descartes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import re\n",
    "#import rasterstats # For zonal statistics. Extracts statistics from rasters files or numpy arrays based on geometries.\n",
    "#import scikitlearn #The best and at the same time easy-to-use Python machine learning library. Regression, classification, dimensionality reductions etc.\n",
    "import folium \n",
    "#import PySAL #The Python Spatial Analysis Library contains a multitude of functions for spatial analysis, statistical modeling and plotting.\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'Data/FAMEWS_12February2019.csv' does not exist: b'Data/FAMEWS_12February2019.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-92e1282e1367>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# READ Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mFAMEWS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data/FAMEWS_12February2019.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0malpha_2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data/Alpha_2.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0malpha_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'Data/FAMEWS_12February2019.csv' does not exist: b'Data/FAMEWS_12February2019.csv'"
     ]
    }
   ],
   "source": [
    "# READ Data \n",
    "FAMEWS = pd.read_csv(\"Data/FAMEWS_12February2019.csv\", sep=',' , encoding='latin-1')\n",
    "alpha_2= pd.read_csv(\"Data/Alpha_2.csv\",sep=',' , encoding='latin-1')\n",
    "alpha_2\n",
    "\n",
    "# Join with country names\n",
    "FAMEWS= FAMEWS.merge(alpha_2,left_on=\"country\",right_on= \"Code\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMEWS.columns\n",
    "#rapsConfirmedFAW, FAWcropdamage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns \n",
    "FAMEWS_new = FAMEWS[['_id','owner','deleted', 'date',\n",
    "       'scouting', 'traps', 'country', 'Name','region', 'locationName',\n",
    "       'trainingReceived', 'cropMain', 'cropVariety',\n",
    "       'panelColumns5Maincropplantingdate', 'cropIrrigation', 'cropFertilizer',\n",
    "       'cropStage', 'cropHealth', 'cropSystem', 'cropFieldSizeUnit',\n",
    "       'rainLastDate', 'latitude', 'longitude', 'rotationIntercroppingCrop',\n",
    "       'cropFieldSize', 'rainAmount', 'trapID', 'trapLocation', 'trapType',\n",
    "       'trapCondition', 'trapLureName', 'trapReplaced', 'trapReplacedDate',\n",
    "       'trapLureReplaced', 'trapKLureReplacedDate', 'btnGpsPosition',\n",
    "       'checked', 'faw', 'sample1PlantsChecked', 'sample2PlantsChecked',\n",
    "       'sample3PlantsChecked', 'sample4PlantsChecked', 'sample5PlantsChecked',\n",
    "       'totalPlantsChecked', 'pestStageFAW', 'fawColumns4Cobdamage',\n",
    "       'fawNaturalEnemies', 'fawLarvaeKilledByNaturalEnemies',\n",
    "       'fawControlUndertaken', 'scoutingPlantsFAW', 'scoutingPercentageFAW',\n",
    "       'totalFAW', 'totalAAW', 'totalBorer', 'scoutingStageFAW', 'userCountry',\n",
    "        'fawCurrentDamage', 'fawPreviousDamage',\n",
    "       'fawControlChemicalPesticideName', 'fawControlChemicalPesticideLitres',\n",
    "       'fawControlLocalTypes', 'fawControlBiopesticideName',\n",
    "       'fawControlBiopesticideLitres', 'sample1FAW', 'sample2FAW',\n",
    "       'sample3FAW', 'sample4FAW', 'sample5FAW', 'access', 'form',\n",
    "       'externalIds', 'created', 'modified','Code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insepecting first few rows \n",
    "FAMEWS_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data Cleaning \n",
    "---\n",
    "\n",
    "## Temporality \n",
    "---\n",
    "\n",
    "* Checking for basic dependencies: Program was launched on 2018 (2018-03-03T17:13:26.000Z). Check how many rows appear before this date and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FAMEWS_new[FAMEWS_new['date'] < '2018-03-03T17:13:26.000Z'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "114 entry points \n",
    "* Notice that 9 rows are from `1970-01-01T23:24:04.000Z` error - data was misread\n",
    "* Notice that 4 rows are from  `2011-11-03T09:41:00.000Z`\n",
    "* Notice that 101 rows are from `2018-01-01T00:51:00.000Z`, `2018-02-27T13:43:00.000Z`, `2018-03-01T14:05:55.000Z` - Trials before release?\n",
    "\n",
    "**Remove 144 entries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMEWS_temp = FAMEWS_new[FAMEWS_new['date'] >= '2018-03-03T17:13:26.000Z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Duplicates \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows \n",
    "len(FAMEWS_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Drop duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMEWS_dup= FAMEWS_temp.drop_duplicates()\n",
    "len(FAMEWS_dup)\n",
    "\n",
    "#removed 10871 rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Select Columns\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\n",
    "**Want to know if it is worth keeping totalFAW, totalAAW, and totalBorer or it was just accounted for in scoutingPlantsFAW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMEWS_dup[FAMEWS_dup[\"totalFAW\"]>=0.0].shape\n",
    "# (21050, 73)- Helps remove NaN values for this case. Also- helped confrimed that there are values on this column. \n",
    "# Worth keeping for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = [\"_id\",'owner', \"date\",\n",
    "            \"Name\",\"country\",\n",
    "            \"region\",\"locationName\",\"latitude\", \"longitude\",\n",
    "            \"scouting\", \"traps\",\"trainingReceived\",\n",
    "            \"cropMain\", \"cropVariety\", \"cropIrrigation\", \n",
    "            \"cropFertilizer\",\"cropStage\",\"cropStage\",\n",
    "            \"cropHealth\", \"cropSystem\", \"cropFieldSizeUnit\", \n",
    "            \"cropFieldSize\", \"rotationIntercroppingCrop\",\n",
    "            \"rainLastDate\",\"rainAmount\", \n",
    "            \n",
    "            \"checked\", \"faw\", \n",
    "            \n",
    "            \"scoutingPlantsFAW\", \"scoutingPercentageFAW\", \n",
    "            \"totalFAW\", \"totalAAW\", \"totalBorer\",\n",
    "           \n",
    "            \"trapType\",\"trapCondition\"]\n",
    "\n",
    "FAMEWS_selected= FAMEWS_dup[selected]\n",
    "FAMEWS_selected.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Transformations\n",
    "\n",
    "* column edits\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \n",
    "**cropFieldSizeUnit [acre/ha] & cropFieldSize [numeric]** - Chose standard field sieze unit. Useful when checking spread/region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMEWS_selected.groupby([\"cropFieldSizeUnit\"]).count()[\"_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from acre to ha - divide acre by 2.471\n",
    "# # from m2 to ha - \t divide the area value by 10000\n",
    "# # from yd2 to ha - for an approximate result, divide the area value by 11959.9\n",
    "\n",
    "by_acre= FAMEWS_selected[FAMEWS_selected[\"cropFieldSizeUnit\"] == \"acre\"]\n",
    "by_acre.insert(21, \"cropFieldSize_ha\", by_acre[\"cropFieldSize\"]/2.471, True) \n",
    "by_acre.insert(21,\"cropFieldSizeUnit_ha\", len(by_acre[\"cropFieldSize\"])*[\"ha\"])\n",
    "\n",
    "by_m2= FAMEWS_selected[FAMEWS_selected[\"cropFieldSizeUnit\"] == \"m2\"]\n",
    "by_m2.insert(21, \"cropFieldSize_ha\", by_m2[\"cropFieldSize\"]/1000, True) \n",
    "by_m2.insert(21,\"cropFieldSizeUnit_ha\", len(by_m2[\"cropFieldSize\"])*[\"ha\"])\n",
    "\n",
    "by_yd2= FAMEWS_selected[FAMEWS_selected[\"cropFieldSizeUnit\"] == \"yd2\"]\n",
    "by_yd2.insert(21, \"cropFieldSize_ha\", by_yd2[\"cropFieldSize\"]/11959.9, True) \n",
    "by_yd2.insert(21,\"cropFieldSizeUnit_ha\", len(by_yd2[\"cropFieldSize\"])*[\"ha\"])\n",
    "\n",
    "\n",
    "by_ha= FAMEWS_selected[FAMEWS_selected[\"cropFieldSizeUnit\"] == \"ha\"]\n",
    "by_ha.insert(21, \"cropFieldSize_ha\", by_ha[\"cropFieldSize\"], True) \n",
    "by_ha.insert(21,\"cropFieldSizeUnit_ha\", len(by_ha[\"cropFieldSize\"])*[\"ha\"])\n",
    "\n",
    "\n",
    "all_dfs = [by_acre, by_m2, by_yd2,by_ha]\n",
    "FAMEWS_selected= pd.concat(all_dfs).reset_index(drop=True)\n",
    "\n",
    "FAMEWS_selected.drop([\"cropFieldSizeUnit\",\"cropFieldSize\"],axis=1,inplace=True)\n",
    "FAMEWS_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. \n",
    "\n",
    "**Replacing NaN values in**\n",
    "\n",
    "* totalFAW\t\n",
    "* totalAAW\t\n",
    "* totalBorer\n",
    "* checked\n",
    "* faw\t\n",
    "* scoutingPlantsFAW\t\n",
    "* scoutingPercentageFAW\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMEWS_selected.faw[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## New Features \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "**days_since_last_rain**\n",
    "\n",
    "**New column** number of days since last rain. Use **rainLastDate**- date-time and get difference from the date in which it was reported **date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from datetime import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date to datetime \n",
    "FAMEWS_selected['rainLastDate']=pd.to_datetime(FAMEWS_selected['rainLastDate'])\n",
    "#convert rainLastDate to datetime\n",
    "FAMEWS_selected['date']=pd.to_datetime(FAMEWS_selected['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract just days variables from date\n",
    "FAMEWS_selected.insert(2,\"date_date\", FAMEWS_selected[\"date\"].apply(lambda x: x.date()), True)  # comment out true to avoid getting a another column \n",
    "\n",
    "# Extract just days variables from rainLastDate_date\n",
    "FAMEWS_selected.insert(25,\"rainLastDate_date\", FAMEWS_selected[\"rainLastDate\"].apply(lambda x: x.date()), True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FAMEWS_selected.insert(26,\"rainLastDate_date\", FAMEWS_selected[\"date_date\"]-FAMEWS_selected[\"rainLastDate_date\"],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMEWS_selected.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. \n",
    "**Days since first reporting**\n",
    "* Need to confirm the date of the first reporting for each country \n",
    "* Alternatevely, can add use the first daye reported using FAMWES as the initial date- but this could be very misleading. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## EDA\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = FAMEWS_selected.groupby([\"Name\"]).count().sort_values(\"_id\", ascending=False)['_id'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = countries.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' We have survey data for {len(countries)} countries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10 ))\n",
    "ax=sns.barplot(x=\"_id\", y=\"Name\", data=countries)\n",
    "ax.set(xlabel='Survey Count', ylabel='Country Name')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training=FAMEWS_selected.groupby([\"trainingReceived\"]).count().sort_values(\"_id\", ascending=False)['_id'].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training.reset_index()\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f' 1. Main training received are from {training[\"trainingReceived\"][0]}, {training[\"_id\"][0]} counts.')\n",
    "print(f' 2. Main training received are from {training[\"trainingReceived\"][1]}, {training[\"_id\"][1]} counts.')\n",
    "print(f' 3. Main training received are from {training[\"trainingReceived\"][2]}, {training[\"_id\"][2]} counts.')\n",
    "print(f' 4. Main training received are from {training[\"trainingReceived\"][3]}, {training[\"_id\"][3]} counts.')\n",
    "print(f' 5. Main training received are from {training[\"trainingReceived\"][4]}, {training[\"_id\"][4]} counts.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMEWS_selected.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_crop=FAMEWS_selected.groupby(\"cropMain\").count().sort_values(\"_id\",ascending=False)['_id'].to_frame().reset_index()\n",
    "\n",
    "print(f' We have {len(by_crop[\"cropMain\"])} crops')\n",
    "print()\n",
    "print(f' The crops that we have are {by_crop[\"cropMain\"].sort_values()}')\n",
    "print('Notice the \"Select\". This means that some farmers did not select a crop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main crop count (All countries)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10 ))\n",
    "ax=sns.barplot(x=\"_id\", y=\"cropMain\", data=by_crop)\n",
    "ax.set(xlabel='count', ylabel='Main Crop')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of crops per country**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_crop1=FAMEWS_selected.groupby([\"Name\",\"cropMain\"]).count().sort_values(\"_id\", ascending=False)['_id'].to_frame()\n",
    "main_crop1= main_crop1.reset_index()\n",
    "main_crop1=main_crop1.sort_values([\"Name\",'_id'], ascending=[True, False])\n",
    "main_crop1.head(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crop per region in each country**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_crop2=FAMEWS_selected.groupby([\"Name\",\"region\",\"cropMain\"]).count().sort_values(\"_id\", ascending=False)['_id'].to_frame()\n",
    "main_crop2= main_crop1.reset_index()\n",
    "main_crop2.sort_values(['Name', '_id'], ascending=[False, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main Crops By Country**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_crop.sort_values(\"_id\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crops = dict()\n",
    "for crop in by_crop.cropMain:\n",
    "    crops[crop] = main_crop1[main_crop1['cropMain'] == crop].sort_values(\"_id\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in crops.keys():    \n",
    "    plt.figure(figsize=(20,10 ))\n",
    "    ax=sns.barplot(x=\"_id\", y=\"Name\", data=crops[key])\n",
    "    ax.set(xlabel='Survey Count', ylabel='Country Name', title=key.upper())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trapsConfirmedFAW, FAWcropdamage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "### FAW by main crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "### FAW by crop stage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "### FAW by crop system "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Buffer Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CRS -- World Mercator, units of meters.\n",
    "from shapely.geometry import Point, Polygon\n",
    "#FAMEWS_new['geometry']= [Point(x,y).buffer(500000) for x,y in zip(FAMEWS_new['longitude'],FAMEWS_new['latitude'])]\n",
    "#FAMEWS_new['geometry']= FAMEWS_new['geometry'].apply(Point)\n",
    "#crs ={'init':'epsg:3395'}\n",
    "geo_FAMEWS= gpd.GeoDataFrame([\n",
    "    {'geometry': Point(x,y).buffer(500000),\"latitude\":y, \"longitude\":x}\n",
    "    for x,y in zip(FAMEWS_new['longitude'],FAMEWS_new['latitude'])])\n",
    "# Previously inside of the Geo Data Frame - FAMEWS_new[[\"Name\", \"date\",\"longitude\",\"latitude\"]],geometry=\"geometry\")\n",
    "print(geo_FAMEWS.head())\n",
    "#geo_FAMEWS['geometry']=geo_FAMEWS.buffer(500000)\n",
    "#geo_FAMEWS.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "# Select Africa and some columns\n",
    "region= world[(world['continent'] != \"South America\") &(world['continent'] != \"North America\")&(world['continent'] != \"Antarctica\")]\n",
    "#region['geometry'].crs=({'init':'epsg:3395'})\n",
    "ax=region.plot(figsize=(50, 50), alpha=0.5, edgecolor='k')\n",
    "geo_FAMEWS.plot(ax=ax, color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make 500km buffer\n",
    "#geo_FAMEWS['geometry']=geo_FAMEWS.buffer(500000)\n",
    "#holes=geo_FAMEWS.buffer(500000)\n",
    "geo_FAMEWS.plot(markersize=20,facecolors='none',edgecolor='r',alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibly locations to look into (coordiates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region.head()\n",
    "#geo_FAMEWS=geo_FAMEWS[[\"Name\",\"date\",\"longitude\",\"latitude\",\"geometry\"]]\n",
    "type(geo_FAMEWS)\n",
    "#newdf = gpd.overlay(region, geo_FAMEWS, how=\"union\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lat top = 19, bottom = -35\n",
    "#long left = -20, right = 52\n",
    "#FAMEWS_new[(FAMEWS_new['latitude'] >=-35)  &  (FAMEWS_new['latitude'] <=19)& (FAMEWS_new['longitude'] <=52)& (FAMEWS_new['longitude'] >= -20)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FAMEWS_unique['region'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of counries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FAMEWS_unique['country'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zambia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zambia_training=Zambia.groupby(['trainingReceived']).count()[[\"_id\"]].reset_index()\n",
    "\n",
    "#--- Total\n",
    "total= sum(Zambia_training[\"_id\"])\n",
    "\n",
    "#---extensionService\n",
    "extensionService= Zambia_training[Zambia_training['trainingReceived']=='extensionService'][\"_id\"]\n",
    "extensionService_prop=(extensionService/total)*100 \n",
    "extensionService_prop\n",
    "\n",
    "#--- FAO\n",
    "fao= Zambia_training[Zambia_training['trainingReceived']=='fao'][\"_id\"]\n",
    "fao_prop=(fao/total)*100 \n",
    "\n",
    "#--- None\n",
    "no_training= Zambia_training[Zambia_training['trainingReceived']=='none'][\"_id\"]\n",
    "no_training_prop=(no_training/total)*100 \n",
    "\n",
    "#---\n",
    "print(extensionService_prop,fao_prop,no_training_prop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zambia.groupby(['trainingReceived']).count()[\"_id\"].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Zambia.groupby(['region']).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ghana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ghana= FAMEWS_unique[FAMEWS_unique['Name']=='Ghana']\n",
    "Ghana.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ghana.groupby(['trainingReceived']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ghana_training=Ghana.groupby(['trainingReceived']).count()[[\"_id\"]].reset_index()\n",
    "\n",
    "Ghana_training.sort_values(\"_id\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Total\n",
    "total= sum(Ghana_training[\"_id\"])\n",
    "\n",
    "#---extensionService\n",
    "extensionService_g= Ghana_training[Ghana_training['trainingReceived']=='extensionService'][\"_id\"]\n",
    "extensionService_g_prop=(extensionService_g/total)*100 \n",
    "extensionService_g_prop\n",
    "\n",
    "#--- FAO\n",
    "fao_ext_g= Ghana_training[Ghana_training['trainingReceived']=='extensionService,fao'][\"_id\"]\n",
    "fao_ext_g_prop=(fao_ext_g/total)*100 \n",
    "\n",
    "\n",
    "\n",
    "#---\n",
    "print(extensionService_g_prop,fao_ext_g_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Ghana.groupby(['region']).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethiopia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ethiopia= FAMEWS_unique[FAMEWS_unique['Name']=='Ethiopia']\n",
    "Ethiopia.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ethiopia_training=Ethiopia.groupby(['trainingReceived']).count()[[\"_id\"]].reset_index()\n",
    "\n",
    "Ethiopia_training.sort_values(\"_id\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--- Total\n",
    "total_e= sum(Ethiopia_training[\"_id\"])\n",
    "\n",
    "#---extensionService\n",
    "extensionService_e= Ethiopia_training[Ghana_training['trainingReceived']=='extensionService'][\"_id\"]\n",
    "extensionService_e_prop=(extensionService_e/total_e)*100 \n",
    "extensionService_e_prop\n",
    "\n",
    "#--- FocalPerson\n",
    "focal_e= Ethiopia_training[Ethiopia_training['trainingReceived']=='focalPerson'][\"_id\"]\n",
    "focal_e_prop=(focal_e/total_e)*100 \n",
    "\n",
    "#--- fao\n",
    "fao_e= Ethiopia_training[Ethiopia_training['trainingReceived']=='fao'][\"_id\"]\n",
    "fao_e_prop=(fao_e/total_e)*100 \n",
    "\n",
    "#--- extensionService,fao\n",
    "#fao_ext_e= Ethiopia_training[(Ethiopia_training['trainingReceived']=='extensionService,fao')& (Ethiopia_training['trainingReceived']=='fao,extensionService')][\"_id\"]\n",
    "fao_ext_e_prop=((641+246)/total_e)*100 \n",
    "\n",
    "\n",
    "#---\n",
    "print(extensionService_e_prop,focal_e_prop,fao_e_prop,fao_ext_e_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Ethiopia.groupby(['region']).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mozambique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gen1[gen1['country']=='MZ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen1[gen1['country']=='MZ'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MZ_unique= gen1[gen1['country']=='MZ'].drop_duplicates()\n",
    "len(MZ_unique)\n",
    "# unique entries - 1467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing in how many variables does the variables differ\n",
    "diff_count = (MZ_unique.iloc[1] == MZ_unique.iloc[0])\n",
    "diff_count.value_counts()\n",
    "# True     49\n",
    "# False    27\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying how are each row distinct (e.g. same user id, but several entries)\n",
    "#diff_count=diff_count.to_frame()\n",
    "diff_count[diff_count[0]==False].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MZ_unique_owner=MZ_unique['owner'].unique()\n",
    "len(MZ_unique_owner)\n",
    "# owners - 90 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MZ_unique_user=MZ_unique['_id'].unique()\n",
    "len(MZ_unique_user)\n",
    "# unqiue ID's-  609 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MZ_unique_form=MZ_unique['form'].unique()\n",
    "len(MZ_unique_form)\n",
    "# unique forms- where am I getting the 382 surveys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
